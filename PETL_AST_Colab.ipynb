{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PETL-AST: Conformer Adapter on ESC-50\n",
        "\n",
        "**Paper**: Parameter-Efficient Transfer Learning of Audio Spectrogram Transformers (Cappellazzo et al., 2024)\n",
        "\n",
        "**Runtime**: Go to **Runtime → Change runtime type → T4 GPU** before running.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.10.0+cu128\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/PETL-AST-Project\n",
            "dataset\t\t  evaluation.py  PETL_AST_Colab.ipynb  src\n",
            "docs\t\t  hparams\t readme.txt\t       utils\n",
            "download_data.sh  main.py\t requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf PETL-AST-Project\n",
        "\n",
        "# Download repo as tarball (more reliable than git clone on Colab)\n",
        "!wget -q https://github.com/yuvalanavi/PETL-AST-Project/archive/refs/heads/main.tar.gz -O repo.tar.gz\n",
        "!tar -xzf repo.tar.gz && mv PETL-AST-Project-main PETL-AST-Project && rm repo.tar.gz\n",
        "\n",
        "%cd PETL-AST-Project\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies (torch is already on Colab — only extra packages get installed)\n",
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download ESC-50 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bash: download_data.sh: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!bash download_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio files: 0\n",
            "Metadata exists: False\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Expected 2000 audio files, got 0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3570795899.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Audio files: {n_files}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Metadata exists: {os.path.isfile(meta_file)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mn_files\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Expected 2000 audio files, got {n_files}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset OK ✓\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Expected 2000 audio files, got 0"
          ]
        }
      ],
      "source": [
        "# Verify dataset structure\n",
        "import os\n",
        "audio_dir = 'data/ESC-50/audio'\n",
        "meta_file = 'data/ESC-50/meta/esc50.csv'\n",
        "n_files = len(os.listdir(audio_dir)) if os.path.isdir(audio_dir) else 0\n",
        "print(f\"Audio files: {n_files}\")\n",
        "print(f\"Metadata exists: {os.path.isfile(meta_file)}\")\n",
        "assert n_files == 2000, f\"Expected 2000 audio files, got {n_files}\"\n",
        "print(\"Dataset OK ✓\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Smoke Test (1 fold, 3 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py \\\n",
        "    --data_path 'data' \\\n",
        "    --dataset_name 'ESC-50' \\\n",
        "    --method 'adapter' \\\n",
        "    --adapter_block 'conformer' \\\n",
        "    --adapter_type 'Pfeiffer' \\\n",
        "    --seq_or_par 'parallel' \\\n",
        "    --reduction_rate_adapter 96 \\\n",
        "    --kernel_size 8 \\\n",
        "    --device cuda \\\n",
        "    --num_folds 1 --num_epochs 3 \\\n",
        "    --save_best_ckpt True --output_path './outputs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Check**: Loss should decrease over 3 epochs. Trainable params should be ~271K.  \n",
        "If this works, proceed to full training below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Full Training (5 folds × 50 epochs)\n",
        "\n",
        "**Estimated time**: ~2-3 hours on T4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean smoke test outputs before full run\n",
        "!rm -rf outputs/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py \\\n",
        "    --data_path 'data' \\\n",
        "    --dataset_name 'ESC-50' \\\n",
        "    --method 'adapter' \\\n",
        "    --adapter_block 'conformer' \\\n",
        "    --adapter_type 'Pfeiffer' \\\n",
        "    --seq_or_par 'parallel' \\\n",
        "    --reduction_rate_adapter 96 \\\n",
        "    --kernel_size 8 \\\n",
        "    --device cuda \\\n",
        "    --save_best_ckpt True --output_path './outputs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Convergence Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python utils/visualization.py --log_dir outputs --output_dir outputs/plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display plots inline\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "for img_path in sorted(glob.glob('outputs/plots/*.png')):\n",
        "    print(img_path)\n",
        "    display(Image(filename=img_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Saved Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python evaluation.py --data_path data --checkpoint_dir outputs --device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Download Results\n",
        "\n",
        "Download checkpoints, logs, and plots to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zip all outputs for download\n",
        "!zip -r outputs_bundle.zip outputs/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('outputs_bundle.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
